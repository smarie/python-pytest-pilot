<?xml version="1.0" encoding="utf-8"?><testsuite errors="0" failures="0" name="pytest" skips="0" tests="14" time="3.806"><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="35" name="test_ensure_pytest_pilot_installed" time="0.2779965400695801"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_ensure_pytest_pilot_installed0/runpytest-0 --trace-config --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_ensure_pytest_pilot_installed0
PLUGIN registered: &lt;_pytest.config.PytestPluginManager object at 0x7fa592d6d278&gt;
PLUGIN registered: &lt;_pytest.config.Config object at 0x7fa590f11f28&gt;
PLUGIN registered: &lt;module &apos;_pytest.mark&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/mark.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.main&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/main.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.terminal&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/terminal.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.runner&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/runner.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.python&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/python.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.pdb&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/pdb.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.unittest&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/unittest.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.capture&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/capture.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.skipping&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/skipping.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.tmpdir&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/tmpdir.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.monkeypatch&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/monkeypatch.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.recwarn&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/recwarn.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.pastebin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/pastebin.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.helpconfig&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/helpconfig.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.nose&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/nose.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.assertion&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/assertion/__init__.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.genscript&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/genscript.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.junitxml&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/junitxml.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.resultlog&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/resultlog.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.doctest&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/doctest.py&apos;&gt;
PLUGIN registered: &lt;module &apos;_pytest.cacheprovider&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/cacheprovider.py&apos;&gt;
PLUGIN registered: &lt;module &apos;pytest_pilot.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&apos;&gt;
PLUGIN registered: &lt;module &apos;pytest_logging.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_logging/plugin.py&apos;&gt;
PLUGIN registered: &lt;module &apos;pytest_html.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_html/plugin.py&apos;&gt;
PLUGIN registered: &lt;module &apos;pytest_harvest.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_harvest/plugin.py&apos;&gt;
PLUGIN registered: &lt;_pytest.capture.CaptureManager object at 0x7fa590190400&gt;
PLUGIN registered: &lt;Session &apos;test_ensure_pytest_pilot_installed0&apos;&gt;
PLUGIN registered: &lt;_pytest.cacheprovider.LFPlugin object at 0x7fa590196c18&gt;
PLUGIN registered: &lt;_pytest.terminal.TerminalReporter object at 0x7fa5901c6198&gt;
PLUGIN registered: &lt;pytest_harvest.plugin.DefaultXDistHarvester object at 0x7fa5901c6cc0&gt;
PLUGIN registered: &lt;_pytest.python.FixtureManager object at 0x7fa5901c6e48&gt;
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1
using: pytest-2.9.2 pylib-1.9.0
setuptools registered plugins:
  pytest-pilot-0.5.1.dev3+g6829991 at /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py
  pytest-logging-2015.11.4 at /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_logging/plugin.py
  pytest-html-1.9.0 at /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_html/plugin.py
  pytest-harvest-1.9.3 at /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_harvest/plugin.py
active plugins:
    nose                : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/nose.py
    pastebin            : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/pastebin.py
    terminal            : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/terminal.py
    session             : &lt;Session &apos;test_ensure_pytest_pilot_installed0&apos;&gt;
    assertion           : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/assertion/__init__.py
    capturemanager      : &lt;_pytest.capture.CaptureManager object at 0x7fa590190400&gt;
    resultlog           : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/resultlog.py
    recwarn             : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/recwarn.py
    skipping            : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/skipping.py
    pytestconfig        : &lt;_pytest.config.Config object at 0x7fa590f11f28&gt;
    runner              : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/runner.py
    140349064113344     : &lt;pytest_harvest.plugin.DefaultXDistHarvester object at 0x7fa5901c6cc0&gt;
    unittest            : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/unittest.py
    tmpdir              : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/tmpdir.py
    140349109883512     : &lt;_pytest.config.PytestPluginManager object at 0x7fa592d6d278&gt;
    html                : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_html/plugin.py
    monkeypatch         : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/monkeypatch.py
    helpconfig          : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/helpconfig.py
    junitxml            : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/junitxml.py
    lfplugin            : &lt;_pytest.cacheprovider.LFPlugin object at 0x7fa590196c18&gt;
    funcmanage          : &lt;_pytest.python.FixtureManager object at 0x7fa5901c6e48&gt;
    python              : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/python.py
    mark                : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/mark.py
    pdb                 : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/pdb.py
    capture             : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/capture.py
    cacheprovider       : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/cacheprovider.py
    harvest             : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_harvest/plugin.py
    doctest             : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/doctest.py
    logging             : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_logging/plugin.py
    terminalreporter    : &lt;_pytest.terminal.TerminalReporter object at 0x7fa5901c6198&gt;
    pilot               : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py
    genscript           : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/genscript.py
    main                : /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/main.py
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_ensure_pytest_pilot_installed0, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collected 0 items

========================= no tests ran in 0.01 seconds =========================
</system-out><system-err>nomatch: &apos;*pytest-pilot-*&apos;
    and: &apos;PLUGIN registered: &lt;_pytest.config.PytestPluginManager object at 0x7fa592d6d278&gt;&apos;
    and: &apos;PLUGIN registered: &lt;_pytest.config.Config object at 0x7fa590f11f28&gt;&apos;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.mark&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/mark.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.main&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/main.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.terminal&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/terminal.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.runner&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/runner.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.python&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/python.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.pdb&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/pdb.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.unittest&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/unittest.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.capture&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/capture.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.skipping&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/skipping.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.tmpdir&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/tmpdir.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.monkeypatch&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/monkeypatch.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.recwarn&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/recwarn.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.pastebin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/pastebin.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.helpconfig&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/helpconfig.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.nose&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/nose.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.assertion&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/assertion/__init__.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.genscript&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/genscript.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.junitxml&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/junitxml.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.resultlog&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/resultlog.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.doctest&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/doctest.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;_pytest.cacheprovider&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/cacheprovider.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;pytest_pilot.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;pytest_logging.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_logging/plugin.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;pytest_html.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_html/plugin.py&apos;&gt;&quot;
    and: &quot;PLUGIN registered: &lt;module &apos;pytest_harvest.plugin&apos; from &apos;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_harvest/plugin.py&apos;&gt;&quot;
    and: &apos;PLUGIN registered: &lt;_pytest.capture.CaptureManager object at 0x7fa590190400&gt;&apos;
    and: &quot;PLUGIN registered: &lt;Session &apos;test_ensure_pytest_pilot_installed0&apos;&gt;&quot;
    and: &apos;PLUGIN registered: &lt;_pytest.cacheprovider.LFPlugin object at 0x7fa590196c18&gt;&apos;
    and: &apos;PLUGIN registered: &lt;_pytest.terminal.TerminalReporter object at 0x7fa5901c6198&gt;&apos;
    and: &apos;PLUGIN registered: &lt;pytest_harvest.plugin.DefaultXDistHarvester object at 0x7fa5901c6cc0&gt;&apos;
    and: &apos;PLUGIN registered: &lt;_pytest.python.FixtureManager object at 0x7fa5901c6e48&gt;&apos;
    and: &apos;============================= test session starts ==============================&apos;
    and: &apos;platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1&apos;
    and: &apos;using: pytest-2.9.2 pylib-1.9.0&apos;
    and: &apos;setuptools registered plugins:&apos;
fnmatch: &apos;*pytest-pilot-*&apos;
   with: &apos;  pytest-pilot-0.5.1.dev3+g6829991 at /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&apos;
</system-err></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="45" name="test_basic_markers_help" time="0.2603917121887207"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_markers_help0/runpytest-0 --markers --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_markers_help0
@pytest.mark.silos: mark test to run *only* when --silos (&apos;silos&apos; option) is set.

@pytest.mark.extender(value): mark test to run *only* when --extender (&apos;extender&apos; option) is set to &lt;value&gt;. &lt;value&gt; should be one of (&apos;red&apos;, &apos;yellow&apos;).

@pytest.mark.hard_filter(value): mark test to run *both* when --hard_filter (&apos;bbb&apos; option) is set to &lt;value&gt; and if --hard_filter is not set.

@pytest.mark.soft_filter(value): mark test to run *both* when --soft_filter (&apos;soft_filter&apos; option) is set to &lt;value&gt; and if --soft_filter is not set.

@pytest.mark.skip(reason=None): skip the given test function with an optional reason. Example: skip(reason=&quot;no way of currently testing this&quot;) skips the test.

@pytest.mark.skipif(condition): skip the given test function if eval(condition) results in a True value.  Evaluation happens within the module global context. Example: skipif(&apos;sys.platform == &quot;win32&quot;&apos;) skips the test if we are on the win32 platform. see http://pytest.org/latest/skipping.html

@pytest.mark.xfail(condition, reason=None, run=True, raises=None, strict=False): mark the the test function as an expected failure if eval(condition) has a True value. Optionally specify a reason for better reporting and run=False if you don&apos;t even want to execute the test function. If only specific exception(s) are expected, you can list them in raises, and if the test fails in other ways, it will be reported as a true failure. See http://pytest.org/latest/skipping.html

@pytest.mark.parametrize(argnames, argvalues): call a test function multiple times passing in different arguments in turn. argvalues generally needs to be a list of values if argnames specifies only one name or a list of tuples of values if argnames specifies multiple names. Example: @parametrize(&apos;arg1&apos;, [1,2]) would lead to two calls of the decorated test function, one with arg1=1 and another with arg1=2.see http://pytest.org/latest/parametrize.html for more info and examples.

@pytest.mark.usefixtures(fixturename1, fixturename2, ...): mark tests as needing all of the specified fixtures. see http://pytest.org/latest/fixture.html#usefixtures 

@pytest.mark.tryfirst: mark a hook implementation function such that the plugin machinery will try to call it first/as early as possible.

@pytest.mark.trylast: mark a hook implementation function such that the plugin machinery will try to call it last/as late as possible.

</system-out><system-err>exact match: &quot;@pytest.mark.silos: mark test to run *only* when --silos (&apos;silos&apos; option) is set.&quot;
nomatch: &quot;@pytest.mark.extender(value): mark test to run *only* when --extender (&apos;extender&apos; option) is set to &lt;value&gt;. &lt;value&gt; should be one of (&apos;red&apos;, &apos;yellow&apos;).&quot;
    and: &apos;&apos;
exact match: &quot;@pytest.mark.extender(value): mark test to run *only* when --extender (&apos;extender&apos; option) is set to &lt;value&gt;. &lt;value&gt; should be one of (&apos;red&apos;, &apos;yellow&apos;).&quot;
nomatch: &quot;@pytest.mark.hard_filter(value): mark test to run *both* when --hard_filter (&apos;bbb&apos; option) is set to &lt;value&gt; and if --hard_filter is not set.&quot;
    and: &apos;&apos;
exact match: &quot;@pytest.mark.hard_filter(value): mark test to run *both* when --hard_filter (&apos;bbb&apos; option) is set to &lt;value&gt; and if --hard_filter is not set.&quot;
nomatch: &quot;@pytest.mark.soft_filter(value): mark test to run *both* when --soft_filter (&apos;soft_filter&apos; option) is set to &lt;value&gt; and if --soft_filter is not set.&quot;
    and: &apos;&apos;
exact match: &quot;@pytest.mark.soft_filter(value): mark test to run *both* when --soft_filter (&apos;soft_filter&apos; option) is set to &lt;value&gt; and if --soft_filter is not set.&quot;
</system-err></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="75" name="test_basic_options_help" time="0.2688455581665039"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_options_help0/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_options_help0 --help --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_options_help0
usage: pytest.py [options] [file_or_dir] [file_or_dir] [...]

positional arguments:
  file_or_dir

general:
  -k EXPRESSION         only run tests which match the given substring
                        expression. An expression is a python evaluatable
                        expression where all names are substring-matched
                        against test names and their parent classes. Example:
                        -k &apos;test_method or test other&apos; matches all test
                        functions and classes whose name contains
                        &apos;test_method&apos; or &apos;test_other&apos;. Additionally keywords
                        are matched to classes and functions containing extra
                        names in their &apos;extra_keyword_matches&apos; set, as well as
                        functions which have names assigned directly to them.
  -m MARKEXPR           only run tests matching given mark expression.
                        example: -m &apos;mark1 and not mark2&apos;.
  --markers             show markers (builtin, plugin and per-project ones).
  -x, --exitfirst       exit instantly on first error or failed test.
  --maxfail=num         exit after first num failures or errors.
  --strict              run pytest in strict mode, warnings become errors.
  -c file               load configuration from `file` instead of trying to
                        locate one of the implicit configuration files.
  --fixtures, --funcargs
                        show available fixtures, sorted by plugin appearance
  --import-mode={prepend,append}
                        prepend/append to sys.path when importing test
                        modules, default is to prepend.
  --pdb                 start the interactive Python debugger on errors.
  --capture=method      per-test capturing method: one of fd|sys|no.
  -s                    shortcut for --capture=no.
  --runxfail            run tests even if they are marked xfail
  --lf, --last-failed   rerun only the tests that failed at the last run (or
                        all if none failed)
  --ff, --failed-first  run all tests but run the last failures first. This
                        may re-order tests and thus lead to repeated fixture
                        setup/teardown
  --cache-show          show cache contents, don&apos;t perform collection or tests
  --cache-clear         remove all cache contents at start of test run.

reporting:
  -v, --verbose         increase verbosity.
  -q, --quiet           decrease verbosity.
  -r chars              show extra test summary info as specified by chars
                        (f)ailed, (E)error, (s)skipped, (x)failed, (X)passed
                        (w)pytest-warnings (p)passed, (P)passed with output,
                        (a)all except pP.
  -l, --showlocals      show locals in tracebacks (disabled by default).
  --report=opts         (deprecated, use -r)
  --tb=style            traceback print mode (auto/long/short/line/native/no).
  --full-trace          don&apos;t cut any tracebacks (default is to cut).
  --color=color         color terminal output (yes/no/auto).
  --durations=N         show N slowest setup/test durations (N=0 for all).
  --pastebin=mode       send failed|all info to bpaste.net pastebin service.
  --junit-xml=path      create junit-xml style report file at given path.
  --junit-prefix=str    prepend prefix to classnames in junit-xml output
  --result-log=path     path for machine-readable result log.
  --html=path           create html report file at given path.

collection:
  --collect-only        only collect tests, don&apos;t execute them.
  --pyargs              try to interpret all arguments as python packages.
  --ignore=path         ignore path during collection (multi-allowed).
  --confcutdir=dir      only load conftest.py&apos;s relative to specified dir.
  --noconftest          Don&apos;t load any conftest.py files.
  --doctest-modules     run doctests in all .py modules
  --doctest-glob=pat    doctests file matching pattern, default: test*.txt
  --doctest-ignore-import-errors
                        ignore doctest ImportErrors

test session debugging and configuration:
  --basetemp=dir        base temporary directory for this test run.
  --version             display pytest lib version and import information.
  -h, --help            show help message and configuration info
  -p name               early-load given plugin (multi-allowed). To avoid
                        loading of plugins, use the `no:` prefix, e.g.
                        `no:doctest`.
  --trace-config        trace considerations of conftest.py files.
  --debug               store internal tracing debug information in
                        &apos;pytestdebug.log&apos;.
  --assert=MODE         control assertion debugging tools. &apos;plain&apos; performs no
                        assertion debugging. &apos;reinterp&apos; reinterprets assert
                        statements after they failed to provide assertion
                        expression information. &apos;rewrite&apos; (the default)
                        rewrites assert statements in test modules on import
                        to provide assert expression information.
  --no-assert           DEPRECATED equivalent to --assert=plain
  --no-magic            DEPRECATED equivalent to --assert=plain
  --genscript=path      create standalone pytest script at given target path.

Logging Configuration:
  --logging-format=LOGGING_FORMAT
                        log format as used by the logging module
  --logging-date-format=LOGGING_DATE_FORMAT
                        log date format as used by the logging module

custom options:
  -Z, --silo            only run tests marked as silo (marked with @silo).
                        Important: if you call `pytest` without this option,
                        tests marked with @silo will *not* be run.
  --hf                  only run tests marked as hf (marked with @hf). If you
                        call `pytest` without this option, tests marked with
                        @hf will *all* be run.
  --envid=NAME          run tests marked as requiring environment NAME (marked
                        with @envid(NAME)), as well as tests not marked with
                        @envid. Important: if you call `pytest` without this
                        option, tests marked with @envid will *not* be run.
  --flavour=NAME        run tests marked as requiring flavour NAME (marked
                        with @flavour(NAME)), as well as tests not marked with
                        @flavour. If you call `pytest` without this option,
                        tests marked with @flavour will *all* be run.


[pytest] ini-options in the next pytest.ini|tox.ini|setup.cfg file:

  markers (linelist)       markers for test functions
  norecursedirs (args)     directory patterns to avoid for recursion
  testpaths (args)         directories to search for tests when no files or dire
  usefixtures (args)       list of default fixtures to be used with this project
  python_files (args)      glob-style file patterns for Python test module disco
  python_classes (args)    prefixes or glob names for Python test class discover
  python_functions (args)  prefixes or glob names for Python test function and m
  xfail_strict (bool)      default for the strict parameter of xfail markers whe
  doctest_optionflags (args) option flags for doctests
  addopts (args)           extra command line options
  minversion (string)      minimally required pytest version
  logging_format (string)  log format as used by the logging module
  logging_date_format (string) log date format as used by the logging module

environment variables:
  PYTEST_ADDOPTS           extra command line options
  PYTEST_PLUGINS           comma-separated plugins to load during startup
  PYTEST_DEBUG             set to enable debug tracing of pytest&apos;s internals


to see available markers type: py.test --markers
to see available fixtures type: py.test --fixtures
(shown according to specified file_or_dir or current dir if not specified)
</system-out><system-err>nomatch: &apos;  -Z, --silo            only run tests marked as silo (marked with @silo).&apos;
    and: &apos;usage: pytest.py [options] [file_or_dir] [file_or_dir] [...]&apos;
    and: &apos;&apos;
    and: &apos;positional arguments:&apos;
    and: &apos;  file_or_dir&apos;
    and: &apos;&apos;
    and: &apos;general:&apos;
    and: &apos;  -k EXPRESSION         only run tests which match the given substring&apos;
    and: &apos;                        expression. An expression is a python evaluatable&apos;
    and: &apos;                        expression where all names are substring-matched&apos;
    and: &apos;                        against test names and their parent classes. Example:&apos;
    and: &quot;                        -k &apos;test_method or test other&apos; matches all test&quot;
    and: &apos;                        functions and classes whose name contains&apos;
    and: &quot;                        &apos;test_method&apos; or &apos;test_other&apos;. Additionally keywords&quot;
    and: &apos;                        are matched to classes and functions containing extra&apos;
    and: &quot;                        names in their &apos;extra_keyword_matches&apos; set, as well as&quot;
    and: &apos;                        functions which have names assigned directly to them.&apos;
    and: &apos;  -m MARKEXPR           only run tests matching given mark expression.&apos;
    and: &quot;                        example: -m &apos;mark1 and not mark2&apos;.&quot;
    and: &apos;  --markers             show markers (builtin, plugin and per-project ones).&apos;
    and: &apos;  -x, --exitfirst       exit instantly on first error or failed test.&apos;
    and: &apos;  --maxfail=num         exit after first num failures or errors.&apos;
    and: &apos;  --strict              run pytest in strict mode, warnings become errors.&apos;
    and: &apos;  -c file               load configuration from `file` instead of trying to&apos;
    and: &apos;                        locate one of the implicit configuration files.&apos;
    and: &apos;  --fixtures, --funcargs&apos;
    and: &apos;                        show available fixtures, sorted by plugin appearance&apos;
    and: &apos;  --import-mode={prepend,append}&apos;
    and: &apos;                        prepend/append to sys.path when importing test&apos;
    and: &apos;                        modules, default is to prepend.&apos;
    and: &apos;  --pdb                 start the interactive Python debugger on errors.&apos;
    and: &apos;  --capture=method      per-test capturing method: one of fd|sys|no.&apos;
    and: &apos;  -s                    shortcut for --capture=no.&apos;
    and: &apos;  --runxfail            run tests even if they are marked xfail&apos;
    and: &apos;  --lf, --last-failed   rerun only the tests that failed at the last run (or&apos;
    and: &apos;                        all if none failed)&apos;
    and: &apos;  --ff, --failed-first  run all tests but run the last failures first. This&apos;
    and: &apos;                        may re-order tests and thus lead to repeated fixture&apos;
    and: &apos;                        setup/teardown&apos;
    and: &quot;  --cache-show          show cache contents, don&apos;t perform collection or tests&quot;
    and: &apos;  --cache-clear         remove all cache contents at start of test run.&apos;
    and: &apos;&apos;
    and: &apos;reporting:&apos;
    and: &apos;  -v, --verbose         increase verbosity.&apos;
    and: &apos;  -q, --quiet           decrease verbosity.&apos;
    and: &apos;  -r chars              show extra test summary info as specified by chars&apos;
    and: &apos;                        (f)ailed, (E)error, (s)skipped, (x)failed, (X)passed&apos;
    and: &apos;                        (w)pytest-warnings (p)passed, (P)passed with output,&apos;
    and: &apos;                        (a)all except pP.&apos;
    and: &apos;  -l, --showlocals      show locals in tracebacks (disabled by default).&apos;
    and: &apos;  --report=opts         (deprecated, use -r)&apos;
    and: &apos;  --tb=style            traceback print mode (auto/long/short/line/native/no).&apos;
    and: &quot;  --full-trace          don&apos;t cut any tracebacks (default is to cut).&quot;
    and: &apos;  --color=color         color terminal output (yes/no/auto).&apos;
    and: &apos;  --durations=N         show N slowest setup/test durations (N=0 for all).&apos;
    and: &apos;  --pastebin=mode       send failed|all info to bpaste.net pastebin service.&apos;
    and: &apos;  --junit-xml=path      create junit-xml style report file at given path.&apos;
    and: &apos;  --junit-prefix=str    prepend prefix to classnames in junit-xml output&apos;
    and: &apos;  --result-log=path     path for machine-readable result log.&apos;
    and: &apos;  --html=path           create html report file at given path.&apos;
    and: &apos;&apos;
    and: &apos;collection:&apos;
    and: &quot;  --collect-only        only collect tests, don&apos;t execute them.&quot;
    and: &apos;  --pyargs              try to interpret all arguments as python packages.&apos;
    and: &apos;  --ignore=path         ignore path during collection (multi-allowed).&apos;
    and: &quot;  --confcutdir=dir      only load conftest.py&apos;s relative to specified dir.&quot;
    and: &quot;  --noconftest          Don&apos;t load any conftest.py files.&quot;
    and: &apos;  --doctest-modules     run doctests in all .py modules&apos;
    and: &apos;  --doctest-glob=pat    doctests file matching pattern, default: test*.txt&apos;
    and: &apos;  --doctest-ignore-import-errors&apos;
    and: &apos;                        ignore doctest ImportErrors&apos;
    and: &apos;&apos;
    and: &apos;test session debugging and configuration:&apos;
    and: &apos;  --basetemp=dir        base temporary directory for this test run.&apos;
    and: &apos;  --version             display pytest lib version and import information.&apos;
    and: &apos;  -h, --help            show help message and configuration info&apos;
    and: &apos;  -p name               early-load given plugin (multi-allowed). To avoid&apos;
    and: &apos;                        loading of plugins, use the `no:` prefix, e.g.&apos;
    and: &apos;                        `no:doctest`.&apos;
    and: &apos;  --trace-config        trace considerations of conftest.py files.&apos;
    and: &apos;  --debug               store internal tracing debug information in&apos;
    and: &quot;                        &apos;pytestdebug.log&apos;.&quot;
    and: &quot;  --assert=MODE         control assertion debugging tools. &apos;plain&apos; performs no&quot;
    and: &quot;                        assertion debugging. &apos;reinterp&apos; reinterprets assert&quot;
    and: &apos;                        statements after they failed to provide assertion&apos;
    and: &quot;                        expression information. &apos;rewrite&apos; (the default)&quot;
    and: &apos;                        rewrites assert statements in test modules on import&apos;
    and: &apos;                        to provide assert expression information.&apos;
    and: &apos;  --no-assert           DEPRECATED equivalent to --assert=plain&apos;
    and: &apos;  --no-magic            DEPRECATED equivalent to --assert=plain&apos;
    and: &apos;  --genscript=path      create standalone pytest script at given target path.&apos;
    and: &apos;&apos;
    and: &apos;Logging Configuration:&apos;
    and: &apos;  --logging-format=LOGGING_FORMAT&apos;
    and: &apos;                        log format as used by the logging module&apos;
    and: &apos;  --logging-date-format=LOGGING_DATE_FORMAT&apos;
    and: &apos;                        log date format as used by the logging module&apos;
    and: &apos;&apos;
    and: &apos;custom options:&apos;
exact match: &apos;  -Z, --silo            only run tests marked as silo (marked with @silo).&apos;
</system-err></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions0-results0]" time="0.2778310775756836"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries0/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries0 -v -s --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries0
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries0, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv PASSED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv PASSED
test_basic_run_queries.py::test_nomark PASSED

===================== 4 passed, 3 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions1-results1]" time="0.27243733406066895"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries1/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries1 -v -s -Z --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries1
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries1, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo PASSED
test_basic_run_queries.py::test_hf SKIPPED
test_basic_run_queries.py::test_yellow_noenv SKIPPED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv SKIPPED
test_basic_run_queries.py::test_nomark SKIPPED

===================== 1 passed, 6 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions2-results2]" time="0.2698400020599365"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries2/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries2 -v -s --silo --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries2
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries2, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo PASSED
test_basic_run_queries.py::test_hf SKIPPED
test_basic_run_queries.py::test_yellow_noenv SKIPPED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv SKIPPED
test_basic_run_queries.py::test_nomark SKIPPED

===================== 1 passed, 6 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions3-results3]" time="0.27491140365600586"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries3/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries3 -v -s --hf --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries3
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries3, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv PASSED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv SKIPPED
test_basic_run_queries.py::test_nomark SKIPPED

===================== 2 passed, 5 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions4-results4]" time="0.27366209030151367"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries4/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries4 -v -s --hf --flavour=red --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries4
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries4, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv SKIPPED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv SKIPPED
test_basic_run_queries.py::test_nomark SKIPPED

===================== 1 passed, 6 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions5-results5]" time="0.2757222652435303"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries5/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries5 -v -s --hf --flavour=yellow --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries5
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries5, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv PASSED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv SKIPPED
test_basic_run_queries.py::test_nomark SKIPPED

===================== 2 passed, 5 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions6-results6]" time="0.2799801826477051"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries6/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries6 -v -s --envid foo --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries6
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries6, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv PASSED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv PASSED
test_basic_run_queries.py::test_nomark PASSED

===================== 4 passed, 3 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions7-results7]" time="0.2759280204772949"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries7/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries7 -v -s --envid=env1 --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries7
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries7, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv PASSED
test_basic_run_queries.py::test_yellow_env1 PASSED
test_basic_run_queries.py::test_env2 SKIPPED
test_basic_run_queries.py::test_red_noenv PASSED
test_basic_run_queries.py::test_nomark PASSED

===================== 5 passed, 2 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="109" name="test_basic_run_queries[cmdoptions8-results8]" time="0.27826857566833496"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries8/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries8 -v -s --flavour=red --envid=env2 --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries8
============================= test session starts ==============================
platform linux -- Python 3.5.6, pytest-2.9.2, py-1.9.0, pluggy-0.3.1 -- /home/travis/miniconda/envs/test-environment/bin/python
cachedir: .cache
rootdir: /tmp/pytest-of-travis/pytest-0/testdir/test_basic_run_queries8, inifile: 
plugins: pilot-0.5.1.dev3+g6829991, logging-2015.11.4, html-1.9.0, harvest-1.9.3
collecting ... collected 7 items

test_basic_run_queries.py::test_silo SKIPPED
test_basic_run_queries.py::test_hf PASSED
test_basic_run_queries.py::test_yellow_noenv SKIPPED
test_basic_run_queries.py::test_yellow_env1 SKIPPED
test_basic_run_queries.py::test_env2 PASSED
test_basic_run_queries.py::test_red_noenv PASSED
test_basic_run_queries.py::test_nomark PASSED

===================== 4 passed, 3 skipped in 0.01 seconds ======================
</system-out></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="135" name="test_nameconflict" time="0.24283528327941895"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_nameconflict0/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_nameconflict0 --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_nameconflict0
</system-out><system-err>Traceback (most recent call last):
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py&quot;, line 17, in &lt;module&gt;
    raise SystemExit(pytest.main())
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 39, in main
    config = _prepareconfig(args, plugins)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 118, in _prepareconfig
    pluginmanager=pluginmanager, args=args)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 724, in __call__
    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 338, in _hookexec
    return self._inner_hookexec(hook, methods, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 333, in &lt;lambda&gt;
    _MultiCall(methods, kwargs, hook.spec_opts).execute()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 595, in execute
    return _wrapped_call(hook_impl.function(*args), self.execute)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 249, in _wrapped_call
    wrap_controller.send(call_outcome)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/helpconfig.py&quot;, line 28, in pytest_cmdline_parse
    config = outcome.get_result()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 278, in get_result
    raise ex[1].with_traceback(ex[2])
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 264, in __init__
    self.result = func()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 596, in execute
    res = hook_impl.function(*args)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 861, in pytest_cmdline_parse
    self.parse(args)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 966, in parse
    self._preparse(args, addopts=addopts)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 937, in _preparse
    args=args, parser=self._parser)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 724, in __call__
    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 338, in _hookexec
    return self._inner_hookexec(hook, methods, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 333, in &lt;lambda&gt;
    _MultiCall(methods, kwargs, hook.spec_opts).execute()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 595, in execute
    return _wrapped_call(hook_impl.function(*args), self.execute)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 249, in _wrapped_call
    wrap_controller.send(call_outcome)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&quot;, line 75, in pytest_load_initial_conftests
    &quot; Conflicting name(s): %s&quot; % (marker, conflicting))
ValueError: Error registering &lt;Pytest marker &apos;color&apos; with CLI option &apos;--color&apos; and decorator &apos;@pytest.mark.color(&lt;color&gt;)&apos;&gt;: a command with this long or short name already exists. Conflicting name(s): [&apos;--color&apos;]
nomatch: &quot;ValueError: Error registering &lt;Pytest marker &apos;color&apos; with CLI option &apos;--color&apos; and decorator &apos;@pytest.mark.color(&lt;color&gt;)&apos;&gt;: a command with this long or short name already exists. Conflicting name(s): [&apos;--color&apos;]&quot;
    and: &apos;Traceback (most recent call last):&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py&quot;, line 17, in &lt;module&gt;&apos;
    and: &apos;    raise SystemExit(pytest.main())&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 39, in main&apos;
    and: &apos;    config = _prepareconfig(args, plugins)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 118, in _prepareconfig&apos;
    and: &apos;    pluginmanager=pluginmanager, args=args)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 724, in __call__&apos;
    and: &apos;    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 338, in _hookexec&apos;
    and: &apos;    return self._inner_hookexec(hook, methods, kwargs)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 333, in &lt;lambda&gt;&apos;
    and: &apos;    _MultiCall(methods, kwargs, hook.spec_opts).execute()&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 595, in execute&apos;
    and: &apos;    return _wrapped_call(hook_impl.function(*args), self.execute)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 249, in _wrapped_call&apos;
    and: &apos;    wrap_controller.send(call_outcome)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/helpconfig.py&quot;, line 28, in pytest_cmdline_parse&apos;
    and: &apos;    config = outcome.get_result()&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 278, in get_result&apos;
    and: &apos;    raise ex[1].with_traceback(ex[2])&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 264, in __init__&apos;
    and: &apos;    self.result = func()&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 596, in execute&apos;
    and: &apos;    res = hook_impl.function(*args)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 861, in pytest_cmdline_parse&apos;
    and: &apos;    self.parse(args)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 966, in parse&apos;
    and: &apos;    self._preparse(args, addopts=addopts)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 937, in _preparse&apos;
    and: &apos;    args=args, parser=self._parser)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 724, in __call__&apos;
    and: &apos;    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 338, in _hookexec&apos;
    and: &apos;    return self._inner_hookexec(hook, methods, kwargs)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 333, in &lt;lambda&gt;&apos;
    and: &apos;    _MultiCall(methods, kwargs, hook.spec_opts).execute()&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 595, in execute&apos;
    and: &apos;    return _wrapped_call(hook_impl.function(*args), self.execute)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 249, in _wrapped_call&apos;
    and: &apos;    wrap_controller.send(call_outcome)&apos;
    and: &apos;  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&quot;, line 75, in pytest_load_initial_conftests&apos;
    and: &apos;    &quot; Conflicting name(s): %s&quot; % (marker, conflicting))&apos;
exact match: &quot;ValueError: Error registering &lt;Pytest marker &apos;color&apos; with CLI option &apos;--color&apos; and decorator &apos;@pytest.mark.color(&lt;color&gt;)&apos;&gt;: a command with this long or short name already exists. Conflicting name(s): [&apos;--color&apos;]&quot;
</system-err></testcase><testcase classname="pytest_pilot.tests.test_main" file="pytest_pilot/tests/test_main.py" line="151" name="test_nameconflict_short" time="0.23277997970581055"><system-out>running: /home/travis/miniconda/envs/test-environment/bin/python /home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/test_nameconflict_short0/runpytest-0 /tmp/pytest-of-travis/pytest-0/testdir/test_nameconflict_short0 --basetemp=/tmp/pytest-of-travis/pytest-0/testdir/basetemp
     in: /tmp/pytest-of-travis/pytest-0/testdir/test_nameconflict_short0
</system-out><system-err>Traceback (most recent call last):
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&quot;, line 85, in pytest_load_initial_conftests
    parser.addoption(*names, action=&quot;store&quot;, metavar=&quot;NAME&quot;, help=marker.cmdhelp)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 462, in addoption
    self._anonymous.addoption(*opts, **attrs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 690, in addoption
    self._addoption_instance(option, shortupper=False)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 700, in _addoption_instance
    raise ValueError(&quot;lowercase shortoptions reserved&quot;)
ValueError: lowercase shortoptions reserved

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest.py&quot;, line 17, in &lt;module&gt;
    raise SystemExit(pytest.main())
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 39, in main
    config = _prepareconfig(args, plugins)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 118, in _prepareconfig
    pluginmanager=pluginmanager, args=args)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 724, in __call__
    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 338, in _hookexec
    return self._inner_hookexec(hook, methods, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 333, in &lt;lambda&gt;
    _MultiCall(methods, kwargs, hook.spec_opts).execute()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 595, in execute
    return _wrapped_call(hook_impl.function(*args), self.execute)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 249, in _wrapped_call
    wrap_controller.send(call_outcome)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/helpconfig.py&quot;, line 28, in pytest_cmdline_parse
    config = outcome.get_result()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 278, in get_result
    raise ex[1].with_traceback(ex[2])
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 264, in __init__
    self.result = func()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 596, in execute
    res = hook_impl.function(*args)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 861, in pytest_cmdline_parse
    self.parse(args)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 966, in parse
    self._preparse(args, addopts=addopts)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/config.py&quot;, line 937, in _preparse
    args=args, parser=self._parser)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 724, in __call__
    return self._hookexec(self, self._nonwrappers + self._wrappers, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 338, in _hookexec
    return self._inner_hookexec(hook, methods, kwargs)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 333, in &lt;lambda&gt;
    _MultiCall(methods, kwargs, hook.spec_opts).execute()
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 595, in execute
    return _wrapped_call(hook_impl.function(*args), self.execute)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/_pytest/vendored_packages/pluggy.py&quot;, line 249, in _wrapped_call
    wrap_controller.send(call_outcome)
  File &quot;/home/travis/miniconda/envs/test-environment/lib/python3.5/site-packages/pytest_pilot/plugin.py&quot;, line 90, in pytest_load_initial_conftests
    &quot;Caught: %r&quot; % (marker, e))
ValueError: Error registering &lt;Pytest marker &apos;a&apos; with CLI option &apos;-a/--a&apos; and decorator &apos;@pytest.mark.a(&lt;a&gt;)&apos;&gt;: a command with this long or short name already exists. Caught: ValueError(&apos;lowercase shortoptions reserved&apos;,)
</system-err></testcase></testsuite>